{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\parentpoller.py:116: UserWarning: Parent poll failed.  If the frontend dies,\n",
      "                the kernel may be left running.  Please let us know\n",
      "                about your system (bitness, Python, etc.) at\n",
      "                ipython-dev@scipy.org\n",
      "  ipython-dev@scipy.org\"\"\")\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nimport tensorflow as tf\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense\\nfrom tensorflow.keras.layers import Dropout\\n*-> both are same.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convolutional Neural Network\n",
    "\n",
    "\n",
    "# Part 1 - Building the CNN\n",
    "\"\"\"*****************************************************************************************************************************\"\"\"\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "*-> both are same.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0612 13:14:25.885506   992 deprecation_wrapper.py:118] From C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(64, 64, 3..., activation=\"relu\")`\n",
      "  \"\"\"\n",
      "W0612 13:14:25.901552   992 deprecation_wrapper.py:118] From C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0612 13:14:25.904558   992 deprecation_wrapper.py:118] From C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0612 13:14:25.920632   992 deprecation_wrapper.py:118] From C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:33: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:39: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1)`\n",
      "W0612 13:14:25.983767   992 deprecation_wrapper.py:118] From C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0612 13:14:26.004307   992 deprecation_wrapper.py:118] From C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0612 13:14:26.011695   992 deprecation.py:323] From C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:182: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'*****************************************************************************************************************************'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialising the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Step 1 - Convolution\n",
    "classifier.add(Convolution2D(32, 3, 3, input_shape = (64, 64, 3), activation = 'relu'))\n",
    "           # 1). Here 32 is number of feature detectors(filter)(convolutional kernel) and it is of 3*3 matrix. \n",
    "\t\t   #    Number of feature detectors = number of features map.\n",
    "\t\t   # 2a). Black and white images are 2-D array and color images are 3-D array.\n",
    "\t\t   # 2). input_shape is format of input images. All the images must be in a same format.\n",
    "\t\t   # 3). In input_shape, 3 indicates color image, 64,64 are the dimensions of input color image.\n",
    "\t\t   #    *-> (64,64), this must be same as in DataPreprocessing.\n",
    "\t\t   #     If we use higher dimensions, model will take too much time to train but our accuracy will increase.\n",
    "\t\t   #     GPU processor will also increse speed.\n",
    "\t\t   # 4). In convolutional layer we use rectifier activation function.\n",
    "\t\t   \n",
    "\n",
    "# Step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "          # 1). pool_size=(2,2) means our pooling matrix is of 2*2 matrix\n",
    "\n",
    "# Adding a second convolutional layer\n",
    "\n",
    "# Adding 2nd Convolution layer for better accuracy.\n",
    "classifier.add(Convolution2D(32, 3, 3, activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection\n",
    "      # 1). Now we will add hidden layer and output layer.We have aleardy created input layer in Flattering step.\n",
    "\t  \n",
    "classifier.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "               # 1). output_dim=128,commonly power of 2.Start from this value and from experiment we will understand to choose value of output_dim.\n",
    "\t\t\t   # 2). output_dim (units) is the number of nodes in hidden layer/ fully connected layer (as same in ANN).\n",
    "\t\t\t   # 3). Rectifier activation function for hidden/fully connected layer.\n",
    "# One can use dropout here also like in ANN to deal with the overfitting problem.\n",
    "\t\t\t   \n",
    "classifier.add(Dense(output_dim = 1, activation = 'sigmoid'))\n",
    "                     # 1). In output layer, if we have 2 categories(like cat, dog), then we will use 1 node/neiron in output layer,\n",
    "\t\t\t\t\t #   and if we have 3 categories (like dog,cat,lion) then we will use 2 nodes/neurons in output layer and likewise.\n",
    "\t\t\t\t\t # 2). sigmoid function for output layer.\n",
    "\t\t\t\t\t \n",
    "\t\t\t\t\t # If we use softmax activation then output_dim=2 and loss = 'sparse_categorical_crossentropy'.\n",
    "\n",
    "# Compiling the CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "                   # Same as in ANN, See ANN\n",
    "\t\t\t\t   # 1). optimizer='adam', this is a algorithm which is used to get optimal weight for neural netwok.\n",
    "\t\t\t\t  #     It is type of sochastic gradeint descent algorithm.\n",
    "\t\t\t\t  # 2). loss= , this is a loss function used in 'adam' algorithm ,\n",
    "\t\t\t\t  #     loss function = (y^ - y)2  -> minimize it , y=actual value, y^=predicted value.\n",
    "\t\t\t\t  #     ,loss='binary_crossentropy' , for 0 and 1 output ,\n",
    "\t\t\t\t  #   for more than 2 output , we use categorical_crossentropy.\n",
    "\n",
    "\"\"\"*****************************************************************************************************************************\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 119 images belonging to 2 classes.\n",
      "Found 108 images belonging to 2 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'*****************************************************************************************************************************'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Part 2 - Fitting the CNN to the images\n",
    "\n",
    "# 1). Dataset should be in the format as given in the folder or in the format given in tensorflow_website folder.\n",
    "# 2). This is the data preprocessing step in CNN.\n",
    "# 3). See keras documentation, copy paste this code from there.\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\t\t   # 1). This step is Image Augmentation.\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "\t\t\t# 1). target_size=(64,64), this must be same as input_shape in Convolution2D class.\t\t\n",
    "\t\t\t# 2). training_set.labels will give the train_labels.\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')\n",
    "\t\t\t# 1). target_size=(64,64), this must be same as input_shape in Convolution2D class.\t\t\t\t\t\t\t\t\t \n",
    "\t\t\t\t\t\t\t\t\n",
    "\n",
    "\"\"\"*****************************************************************************************************************************\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  \n",
      "C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=<keras_pre..., steps_per_epoch=3, epochs=5, validation_steps=108)`\n",
      "  \n",
      "W0612 13:17:20.023061   992 deprecation_wrapper.py:118] From C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increase the number of epoch and dataset for more accuracy.\n",
      "      As I have only 4 RAM so I am using epoch=5 only, incearse it to 50 for more accuracy. \n",
      "Epoch 1/5\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.9209 - acc: 0.5312 - val_loss: 0.7073 - val_acc: 0.5000\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.7455 - acc: 0.4397 - val_loss: 0.7143 - val_acc: 0.5000\n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.7097 - acc: 0.4641 - val_loss: 0.6961 - val_acc: 0.5000\n",
      "Epoch 4/5\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.6945 - acc: 0.4779 - val_loss: 0.6930 - val_acc: 0.5000\n",
      "Epoch 5/5\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.6933 - acc: 0.5000 - val_loss: 0.6926 - val_acc: 0.5185\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'*****************************************************************************************************************************'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the classifier to training set.\n",
    "print(\"\"\"Increase the number of epoch and dataset for more accuracy.\n",
    "      As I have only 4 RAM so I am using epoch=5 only, incearse it to 50 for more accuracy. \"\"\")\n",
    "classifier.fit_generator(training_set,       # training_set is our generator, which contains both train_images and train_labels.\n",
    "                         samples_per_epoch = 119,\n",
    "                         nb_epoch = 5,\n",
    "                         validation_data = test_set,\n",
    "                         nb_val_samples = 108)   # nb_val_samples = validation_steps. \n",
    "\t\t# 1). Here we are fitting the model and also validating on the test set.\n",
    "        # 2). If we only need to fit then only use classifier.fit().\n",
    "\t\t# 3). samples_per_epoch is the number of images in the training set.\n",
    "\t\t# 4). nb_epoch is same as in ANN i.e. the number of round.\n",
    "\t\t# 5). validation_data on test set, it is equalavent to k-fold.\n",
    "\t\t# 6). nb_val_samples is the number of images in test set.\n",
    "# 1). If we have both train_images and train_labels then use ,\n",
    "#            model.fit(train_images, train_labels)\t\t\n",
    "# See Tensorflow_website folder.\n",
    "\t\t\t\t\t\t \n",
    "\"\"\"*****************************************************************************************************************************\"\"\"\t\t\t\t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99362516]]\n",
      "{'cats': 0, 'dogs': 1}\n",
      "The image is of\t cat\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'****************************************************************************************************************************************'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Part 3 - Making new predictions\n",
    "\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('dataset/single_prediction/cat_or_dog_2.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)   # Converting the image into array.\n",
    "test_image = np.expand_dims(test_image, axis = 0)   # Adding one extra dimension (now total 4 dimensions), without it we will get error.\n",
    "result = classifier.predict(test_image)\n",
    "print(result)\n",
    "\n",
    "map = training_set.class_indices  \n",
    "print(map)   # By this we will get information about mapping of dog and cat with 1 and 0 in dictionary format.\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'\n",
    "\n",
    "print(f\"The image is of\\t {prediction}\")\n",
    "\n",
    "\"\"\"****************************************************************************************************************************************\"\"\"\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ==============================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
